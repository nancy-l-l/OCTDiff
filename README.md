# OCTDiff
At Columbia University’s Medical School, I worked in the Artificial Intelligence 4 Vision Science Lab. We aim to increase the accessibility of Ophthalmic care. I implemented the downstream classification to assess the diagnostic quality of scans enhanced by our diffusion architecture.

I performed downstream disease classification using images generated by OCTDiff to
demonstrate the diffusion model's real-world utility in clinical applications. To reduce model bias, we trained three
classification architectures: ViT, CNN, and SwinT on three domains: (1)
high-resolution images from commercial OCT devices, (2) low-resolution images from portable
OCT devices, OCTDiff enhanced images. We performed 5-fold cross-validation for each
model-dataset pair, with the results shown in the Table above, and we conducted Mann–Whitney U tests
to assess statistical significance. This evaluation was conducted independently for two representative
ophthalmic tasks: glaucoma diagnosis and age-related macular degeneration (AMD) classification. Both of which are widely studied in AI ophthalmology, as they are the top two
causes of blindness worldwide.
Among the six models trained on high-resolution images, three showed no statistically significant difference, with the simplest vanilla CNN performing equally well in accuracy compared to counterparts
trained on OCTDiff-generated images. In contrast, models trained on low-resolution portable OCT
images exhibited a statistically significant drop. BBDM is selected as a representative of SR baselines,
which was outperformed by OCTDiff in 5 out of 6 rows. These comparisons highlight OCTDiff’s
ability to transform previously suboptimal portable OCT scans into diagnostically reliable images,
indicating that our method can closely match gold-standard OCT-image quality, or even exceed the
performance achieved by commercial high-resolution scans.



